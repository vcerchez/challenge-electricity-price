{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from fast_soft_sort.pytorch_ops import soft_rank\n",
    "\n",
    "# from help_spearman_proxy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE for SLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2078, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([1., 2., 3.])\n",
    "\n",
    "x = torch.tensor([3., 4., 5.], requires_grad=True)\n",
    "a = torch.tensor(-1.1, requires_grad=True)\n",
    "b = torch.tensor(5.7, requires_grad=True)\n",
    "y_hat = a * x + b\n",
    "# y.requires_grad = True\n",
    "l = (y - y_hat).norm()\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.9279, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-((y - y_hat) * x).sum() / l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-3.9279),)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = torch.autograd.grad(l, a)\n",
    "grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE for soft ranks and SLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8284, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = 1.0\n",
    "\n",
    "y = torch.tensor([[1., 2., 3.]], requires_grad=True)\n",
    "a = torch.tensor(-1., requires_grad=True)\n",
    "y_hat = a * y\n",
    "\n",
    "l = (soft_rank(y, regularization_strength=rs) - soft_rank(y_hat, regularization_strength=rs)).norm()\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4142,  0.0000,  1.4142]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.grad(l, y)[0]#.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35355339059327373"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/np.sqrt(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vladimir.cerchez\\Desktop\\challenge_prix_electricite\\src\\grad_sign.ipynb Cell 11\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vladimir.cerchez/Desktop/challenge_prix_electricite/src/grad_sign.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m l \u001b[39m=\u001b[39m soft_rank(t, regularization_strength\u001b[39m=\u001b[39mrs)[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vladimir.cerchez/Desktop/challenge_prix_electricite/src/grad_sign.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m grad \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(l, t, create_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/vladimir.cerchez/Desktop/challenge_prix_electricite/src/grad_sign.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(grad[\u001b[39m0\u001b[39m], t)\n",
      "File \u001b[1;32mc:\\Users\\vladimir.cerchez\\AppData\\Local\\miniconda3\\envs\\spearman-proxy\\Lib\\site-packages\\torch\\autograd\\__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m _vmap_internals\u001b[39m.\u001b[39m_vmap(vjp, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, allow_none_pass_through\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[0;32m    302\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 303\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39m_execution_engine\u001b[39m.\u001b[39mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    304\u001b[0m         t_outputs, grad_outputs_, retain_graph, create_graph, t_inputs,\n\u001b[0;32m    305\u001b[0m         allow_unused, accumulate_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "rs = 1.\n",
    "\n",
    "t = torch.tensor([[1.2, 2.]], requires_grad=True)\n",
    "soft_rank(t, regularization_strength=rs)\n",
    "\n",
    "l = soft_rank(t, regularization_strength=rs)[0, 0]\n",
    "\n",
    "grad = torch.autograd.grad(l, t, create_graph=True)\n",
    "torch.autograd.grad(grad[0], t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1000, 1.9000]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_rank(torch.tensor([[1.2, 2.]]), regularization_strength=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.4000]),)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.1], requires_grad=True)\n",
    "a = torch.tensor([0.7], requires_grad=True)\n",
    "y = a * x**2\n",
    "grad = torch.autograd.grad(y, x, create_graph=True)\n",
    "hess = torch.autograd.grad(grad[0], x)\n",
    "hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vladimir.cerchez\\Desktop\\challenge_prix_electricite\\src\\grad_sign.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vladimir.cerchez/Desktop/challenge_prix_electricite/src/grad_sign.ipynb#X30sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m (r \u001b[39m-\u001b[39m r_hat)\u001b[39m.\u001b[39mnorm()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vladimir.cerchez/Desktop/challenge_prix_electricite/src/grad_sign.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m grad \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mjacobian(loss, y_hat)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/vladimir.cerchez/Desktop/challenge_prix_electricite/src/grad_sign.ipynb#X30sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m hess \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mhessian(loss, y_hat)\n",
      "File \u001b[1;32mc:\\Users\\vladimir.cerchez\\AppData\\Local\\miniconda3\\envs\\spearman-proxy\\Lib\\site-packages\\torch\\autograd\\functional.py:826\u001b[0m, in \u001b[0;36mhessian\u001b[1;34m(func, inputs, create_graph, strict, vectorize, outer_jacobian_strategy)\u001b[0m\n\u001b[0;32m    823\u001b[0m     _check_requires_grad(jac, \u001b[39m\"\u001b[39m\u001b[39mjacobian\u001b[39m\u001b[39m\"\u001b[39m, strict\u001b[39m=\u001b[39mstrict)\n\u001b[0;32m    824\u001b[0m     \u001b[39mreturn\u001b[39;00m jac\n\u001b[1;32m--> 826\u001b[0m res \u001b[39m=\u001b[39m jacobian(jac_func, inputs, create_graph\u001b[39m=\u001b[39mcreate_graph, strict\u001b[39m=\u001b[39mstrict, vectorize\u001b[39m=\u001b[39mvectorize,\n\u001b[0;32m    827\u001b[0m                strategy\u001b[39m=\u001b[39mouter_jacobian_strategy)\n\u001b[0;32m    828\u001b[0m \u001b[39mreturn\u001b[39;00m _tuple_postprocess(res, (is_inputs_tuple, is_inputs_tuple))\n",
      "File \u001b[1;32mc:\\Users\\vladimir.cerchez\\AppData\\Local\\miniconda3\\envs\\spearman-proxy\\Lib\\site-packages\\torch\\autograd\\functional.py:591\u001b[0m, in \u001b[0;36mjacobian\u001b[1;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[0;32m    588\u001b[0m is_inputs_tuple, inputs \u001b[39m=\u001b[39m _as_tuple(inputs, \u001b[39m\"\u001b[39m\u001b[39minputs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mjacobian\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    589\u001b[0m inputs \u001b[39m=\u001b[39m _grad_preprocess(inputs, create_graph\u001b[39m=\u001b[39mcreate_graph, need_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 591\u001b[0m outputs \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39minputs)\n\u001b[0;32m    592\u001b[0m is_outputs_tuple, outputs \u001b[39m=\u001b[39m _as_tuple(outputs,\n\u001b[0;32m    593\u001b[0m                                       \u001b[39m\"\u001b[39m\u001b[39moutputs of the user-provided function\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    594\u001b[0m                                       \u001b[39m\"\u001b[39m\u001b[39mjacobian\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    595\u001b[0m _check_requires_grad(outputs, \u001b[39m\"\u001b[39m\u001b[39moutputs\u001b[39m\u001b[39m\"\u001b[39m, strict\u001b[39m=\u001b[39mstrict)\n",
      "File \u001b[1;32mc:\\Users\\vladimir.cerchez\\AppData\\Local\\miniconda3\\envs\\spearman-proxy\\Lib\\site-packages\\torch\\autograd\\functional.py:822\u001b[0m, in \u001b[0;36mhessian.<locals>.jac_func\u001b[1;34m(*inp)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[39mif\u001b[39;00m outer_jacobian_strategy \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mforward-mode\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    819\u001b[0m     \u001b[39m# _grad_preprocess requires create_graph=True and input to require_grad\u001b[39;00m\n\u001b[0;32m    820\u001b[0m     \u001b[39m# or else the input will be detached\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     inp \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(t\u001b[39m.\u001b[39mrequires_grad_(\u001b[39mTrue\u001b[39;00m) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inp)\n\u001b[1;32m--> 822\u001b[0m jac \u001b[39m=\u001b[39m jacobian(ensure_single_output_function, inp, create_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    823\u001b[0m _check_requires_grad(jac, \u001b[39m\"\u001b[39m\u001b[39mjacobian\u001b[39m\u001b[39m\"\u001b[39m, strict\u001b[39m=\u001b[39mstrict)\n\u001b[0;32m    824\u001b[0m \u001b[39mreturn\u001b[39;00m jac\n",
      "File \u001b[1;32mc:\\Users\\vladimir.cerchez\\AppData\\Local\\miniconda3\\envs\\spearman-proxy\\Lib\\site-packages\\torch\\autograd\\functional.py:686\u001b[0m, in \u001b[0;36mjacobian\u001b[1;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[0;32m    684\u001b[0m jac_i: Tuple[List[torch\u001b[39m.\u001b[39mTensor]] \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m([] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(inputs)))  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    685\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(out\u001b[39m.\u001b[39mnelement()):\n\u001b[1;32m--> 686\u001b[0m     vj \u001b[39m=\u001b[39m _autograd_grad((out\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)[j],), inputs,\n\u001b[0;32m    687\u001b[0m                         retain_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, create_graph\u001b[39m=\u001b[39mcreate_graph)\n\u001b[0;32m    689\u001b[0m     \u001b[39mfor\u001b[39;00m el_idx, (jac_i_el, vj_el, inp_el) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(jac_i, vj, inputs)):\n\u001b[0;32m    690\u001b[0m         \u001b[39mif\u001b[39;00m vj_el \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\vladimir.cerchez\\AppData\\Local\\miniconda3\\envs\\spearman-proxy\\Lib\\site-packages\\torch\\autograd\\functional.py:167\u001b[0m, in \u001b[0;36m_autograd_grad\u001b[1;34m(outputs, inputs, grad_outputs, create_graph, retain_graph, is_grads_batched)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mNone\u001b[39;00m,) \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(inputs)\n\u001b[0;32m    166\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(new_outputs, inputs, new_grad_outputs, allow_unused\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    168\u001b[0m                                create_graph\u001b[39m=\u001b[39mcreate_graph, retain_graph\u001b[39m=\u001b[39mretain_graph,\n\u001b[0;32m    169\u001b[0m                                is_grads_batched\u001b[39m=\u001b[39mis_grads_batched)\n",
      "File \u001b[1;32mc:\\Users\\vladimir.cerchez\\AppData\\Local\\miniconda3\\envs\\spearman-proxy\\Lib\\site-packages\\torch\\autograd\\__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m _vmap_internals\u001b[39m.\u001b[39m_vmap(vjp, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, allow_none_pass_through\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[0;32m    302\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 303\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39m_execution_engine\u001b[39m.\u001b[39mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    304\u001b[0m         t_outputs, grad_outputs_, retain_graph, create_graph, t_inputs,\n\u001b[0;32m    305\u001b[0m         allow_unused, accumulate_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\vladimir.cerchez\\AppData\\Local\\miniconda3\\envs\\spearman-proxy\\Lib\\site-packages\\torch\\autograd\\function.py:274\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mImplementing both \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbackward\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mvjp\u001b[39m\u001b[39m'\u001b[39m\u001b[39m for a custom \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    271\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mFunction is not allowed. You should only implement one \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    272\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mof them.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    273\u001b[0m user_fn \u001b[39m=\u001b[39m vjp_fn \u001b[39mif\u001b[39;00m vjp_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m Function\u001b[39m.\u001b[39mvjp \u001b[39melse\u001b[39;00m backward_fn\n\u001b[1;32m--> 274\u001b[0m \u001b[39mreturn\u001b[39;00m user_fn(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\vladimir.cerchez\\Desktop\\challenge_prix_electricite\\src\\fast_soft_sort\\pytorch_ops.py:40\u001b[0m, in \u001b[0;36mwrap_class.<locals>.NumpyOpWrapper.backward\u001b[1;34m(ctx, grad_output)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward\u001b[39m(ctx, grad_output):\n\u001b[1;32m---> 40\u001b[0m   \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mfrom_numpy(ctx\u001b[39m.\u001b[39mnumpy_obj\u001b[39m.\u001b[39mvjp(grad_output\u001b[39m.\u001b[39mnumpy()))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "rs = 1.\n",
    "\n",
    "y = torch.tensor([[2., 1.]])\n",
    "y_hat = torch.tensor([[1.2, 2.]], requires_grad=True)\n",
    "\n",
    "def loss(y_hat):\n",
    "  r = soft_rank(y, regularization_strength=rs)\n",
    "  r_hat = soft_rank(y_hat, regularization_strength=rs)\n",
    "  return (r - r_hat).norm()\n",
    "\n",
    "grad = torch.autograd.functional.jacobian(loss, y_hat)\n",
    "hess = torch.autograd.functional.hessian(loss, y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spearman-proxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
